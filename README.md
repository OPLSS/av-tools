# OPLSS 2021 Videography

This document describes the equipment and procedures we use to record
the [Oregon Programming Languages Summer
School](https://www.cs.uoregon.edu/research/summerschool/) sessions
and publish the recordings.

## Special Circumstances

Due to the pandemic, OPLSS occurred entirely by Zoom video
conference. Thus, we recorded all of the presentations within Zoom.

## Tools

I used these tools:

  * Kdenlive for producing the titles and rendering the final videos
  * VidCutter to extract each session from Zoom's raw videos

## Processing

### Acquire raw video

Download raw videos from oregon.zoom.us. Jim provided the URLs.

Use VidCutter to extract each session from the raw videos.

Organize the videos by date and speaker.

### Acquire imagery

Find a royalty-free image as a background for the titles. I chose
[...](...).

### Acquire music

Find royalty-free music to play beneath the prologue and epilogue
videos. I chose []() for the prologue and []() for the epilogue.

### Create prologue video

/pending/

### Create epilogue video

/pending/

## EVERYTHING AFTER THIS HEADING PERTAINS TO 2019

## A/V Personnel

The OPLSS coordinator should designate a lead videographer and an
assistant. The lead is responsible for all aspects of operating and
maintaining the A/V equipment, as well as editing and publishing the
recordings. The assistant should be familiar with this document in
order to record sessions if the lead is unavailable.

## A/V Equipment Inventory

We used the following audio-visual equipment to record OPLSS sessions:

  * [Canon EOS 80D digital SLR camera](https://www.usa.canon.com/internet/portal/us/home/products/details/cameras/eos-dslr-and-mirrorless-cameras/dslr/eos-80d) kit -- body, lens, batteries,
    charger -- borrowed from the university's media center
  * at least three SD cards, each at least 128 GB capacity _(for
    recording and storing videos)_
  * [Fifine wireless microphone](https://fifinemicrophone.com/collections/wireless-systems/products/lavalier-microphone-with-head-worn-unit-k037b) _(connected to the camera)_
  * [Shure SLX-1 wireless microphone](https://www.shure.com/en-US/products/wireless-systems/slx_wireless/slx1), borrowed from the Knight Law A/V
    department _(connected to the room's PA system)_
  * [Manfrotto Compact Advanced tripod](https://www.manfrotto.us/compact-advanced-aluminium-tripod-with-3-way-head-black), also borrowed from the media center
  * headphones _(to monitor the camera's audio input)_
  * alkaline AA and AAA batteries _(for the microphone transmitters and receivers)_
  * power strip
  * HDMI video adapters:
	* USB-C
    * Apple Thunderbolt
    * Apple Mini-DisplayPort
  * laser pointer

The videographer should supply computing hardware for post-OPLSS video
processing.

### Device battery inventory

The equipment uses a variety of batteries. The videographer should
maintain the spare supply in a way that anticipates failure and rapid
battery replacement.

Battery inventory:

| Device                 | Battery Type |
|------------------------|--------------|
| EOS 80D                | rechargeable |
| Fifine mic transmitter | AA           |
| Fifine mic receiver    | AAA          |
| Shure mic transmitter  | AA           |
| Shure mic receiver     | AAA          |

The mic transmitters come equipped with indicators of the remaining
charge. They typically run at least three days before falling below
50%, at which time they should be changed.

The Fifine mic's receiver does not indicate battery charge and will
fail without warning. It typically runs at least two days.

## OPLSS venue

OPLSS used room 175 in the Knight Law building, an auditorium that
seats about one hundred. The room was equipped with a projector and
public address system. A locked side room contained audio-visual
equipment and served as storage for our valuables.  A touch-screen
panel adjacent to the equipment room controlled the room's projector
and PA system.

The room's acoustics absorbed the instructor's voice, especially when
facing away from the audience. We therefore used a wireless microphone
connected to the PA system. This entailed asking the instructors to
wear two microphones and transmitters. Most complied, but several
refused.

The law school has dedicated A/V and IT staff who can assist with
issues.

## Pre-OPLSS rehearsal

At least one week prior to the first OPLSS session, the videographer
should arrange a time with the event coordinator to visit the room and
rehearse recording a session. This is vital to understanding the
room's layout, lighting, and A/V control systems.

The coordinator invite the Knight Law A/V lead to the rehearsal. The
coordinator should bring the A/V equipment (camera, microphone, and
tripod).

The videographer lead and assistant should do all of the following
during the rehearsal session:

  * Mount the camera on its tripod
  * Connect the wireless microphone and headphones to the camera
  * Record someone speaking with the wireless microphone
  * Practice unplugging the camera microphone, recording with the
    camera's built-in mic, replacing the battery, and reconnecting the
    mic. This is necessary because the camera's microphone will
    occasionally fail due to battery exhaustion, accidental power-off,
    interference, and other unexpected circumstances.
  * Understand how to use the PA system mic
  * Monitor the recording with headphones
  * Cycle the room's projector controls. Connect a laptop to the
    projector.

### Preparing to record a session

Arrive at the lecture room at least 15 minutes prior to each session's
start time. Do all of the following during set-up:

  * Prepare the camera:
    * Mount the camera to its tripod
    * Power it on
    * Verify the card's storage capacity
  * Insert a fully-charged battery and charge the depleted battery
  * Set the zoom and focus
  * Connect the wireless microphone and headphones to the
    camera. Power on the transmitter and check its battery level. If
    below 50%, replace the batteries.
  * Power on the mic transmitters and the room's A/V system
  * Verify the camera mic's connection to its receiver -- when
    successful, the receiver's status light will glow solid orange.
  * Verify that the PA mic is broadcasting through the room's PA
    system. If the speaker plans to project and needs a laser pointer,
    place it on the podium.
  * Assist the instructor with fitting the lapel mics
  * Stage a pair of AAA batteries by the camera in case the receiver
    fails mid-session
  * Stage a fully-charged camera battery by the camera
  * Using the headphones, verify that the instructor is audible via
    the camera's mic

### Recording a session

  * Start recording when the instructor begins speaking, ideally
    slightly before
  * Record events that occur during the session:
    * The length of each video file. See below for notes about the
      camera's 30-minute video length limit.
    * Camera or microphone problems
    * Any other events relevant to post-OPLSS video processing

#### Framing, pan, and zoom guidelines

The videographer should operate the camera in a way that maximizes the
instructor, white board writing, and projected content in the frame,
while also minimizing camera motion. This as an art, as instructors
vary in how often and how far they move laterally. Instructors who
move frequently and unpredictably present the greatest challenge,
sometimes requiring rapid panning. To the greatest extent possible,
pan and zoom strategically to anticipate the instructor's lateral
moves.

When the instructor is writing on a board, the operator should include
the instructor and the relevant board content in the frame at all
times. The zoom level depends on two primary factors:

  1. How size of the instructor's writing
  2. How much horizontal space the instructor is using for relevant content

Experienced lecturers tend to use half of a board at a time and
minimize lateral motion, which permits the videographer to establish a
static frame slightly wider than the relevant content. The instructor can
move a few steps away from the content and remain within the frame.

When the instructor is projecting, attempt to establish a frame including
the screen and at least the instructor's head. Most instructors will gesture
at the screen and capturing those gestures is valuable. The zoom level
will depend on each slide's legibility. If the instructor moves, the
operator should use pan and zoom to balance the instructor and the screen
in the frame.

#### 30-minute video file limit

The EOS 80D stops recording after 30 minutes. The videographer must
monitor the camera's timer and attempt to stop and restart the
recording during a pause, ideally at a topical boundary, in order to
provide a smooth transition for viewers. Cycle the recording any time
after 25 minutes.

#### Common problems and solutions

The camera microphone's receiver offers no battery charge
indicator. It therefore fails without warning. When it does, the
status light will flash green. One pair of batteries typically lasts
about two days.

When the batteries exhaust themselves, immediately unplug it and
continue recording with the camera's built-in mic. Replace them as
quickly and quietly as possible, then reconnect the mic. If the
problem lies with the transmitter, *do not* stop the instructor:
instead, address the issue after the session.

### Maintaining session metadata

The videographer should maintain metadata about the sessions, namely:

  * a count of the total number of sessions
  * a session identifier in `<day>.<session number>` format
  * the instructor's name and affiliation
  * the lecture's topic
  * the session's date, start time, and end time
  * the card ID on which the session was recorded
  * the length of each video file, in minutes
  * notes about the recording: audio or video problems, etc.

### Securely storing A/V equipment

We locked the A/V equipment in the venue's equipment room. The OPLSS
coordinator was responsible for managing the key. The lead should
acquire the key from the coordinator as early as possible before a
session to retrieve the equipment.

## Video Publishing Procedures

We published the videos to two locations:

  * The [University of Oregon's OPLSS site](https://www.cs.uoregon.edu/research/summerschool/summer18/topics.php)
  * The [`OPLSS` YouTube channel](https://www.youtube.com/channel/UCDe6N9R7U-RYWA57wzJQ2SQ)

### Publishing to the OPLSS site

The OPLSS coordinator is the only person with credentials on the
university's OPLSS site. Historically, the coordinator uploaded raw
video files every evening. The videographer should give the day's data
card to the coordinator at the conclusion of each day's sessions and
retrieve the card from the coordinator before recording the next day.

### Publishing to YouTube

Publishing the videos to YouTube is a complicated process involving
multiple software components and a considerable amount of manual effort.

#### Creating title graphics

The videographer should create title graphics to accompany the session
videos.  We refer to them here as _title cards_ or _cards_. We created
one set of cards that appear in every video, along with a set of cards
unique to each session.

The common cards are:

  * main title
  * sponsors
  * copyright notice

The unique cards are:

  * session title
  * editor's notes

Each session card stated the topic, instructor, instructor's
affiliation, lecture date, and session number on that date.

The main title, session, and sponsor cards appeared before the session
video. The copyright card appeared after the video.

The videographer used [GIMP](https://gimp.org/) to create the cards
and `xcf2png` from [xcftools](http://henning.makholm.net/xcftools/) to
convert GIMP's XCF files to PNG format.

The OPLSS font is named [_PT Mono
Bold_](https://www.1001fonts.com/pt-mono-font.html#character-map-bold). "PT"
is a reference to [ParaType](https://www.paratype.com/), the font's
creator.

The OPLSS font and logo use these colors:

| *Color* | *RGB (hex)* |
|---------|-------------|
| green   | 248c68      |
| grey    | 828282      |
| yellow  | fee123      |

See the [session schedule](configuration/schedule.csv).

#### Generating the final videos

The videographer used [`FFmpeg`](https://ffmpeg.org/) and a set of
custom tools to combine the raw video files and title graphics into
files suitable for uploading to YouTube. The custom tools reside in
this repository's `bin` directory. They're written in Ruby and require
at least Ruby 2.4.

After generating the title cards, the videographer used FFmpeg to
convert them to MPEG-4 videos, then concatenated the card videos with
each session's video files.

The video elements appear in this sequence. The parenthesized number
is the element's running time:

  * main title card _(6s)_
  * session title card _(6s)_
  * sponsors card _(6s)_
  * session video segments _(~90m)_
  * copyright card _(6s)_

As noted earlier, the main, sponsors, and copyright cards were the
same for all videos, whereas the session titles and recordings were
unique to each session.

The custom tools partially automated the rendering process:

  * `from_image` converted an image file into a short video with the
    same encoding as the session recordings. The lead used this tool
    to render title graphics as videos.
  * `sequence` generated an ASCII sequence file in a format suitable
    for input to FFmpeg's
    [concat](https://ffmpeg.org/ffmpeg-filters.html#concat). This file
    specified the video concatenation sequence.
  * `render` used FFmpeg's
    [concat](https://ffmpeg.org/ffmpeg-filters.html#concat) and a
    sequence file to render a YouTube-compatible file. See also
    [commentary on FFmpeg's concatenation
    options](https://trac.ffmpeg.org/wiki/Concatenate).

Due to the large file sizes and the time required to process the
videos, the videographer should strive to maximally automate the video
pipeline.

#### Storage considerations

The camera stored raw video files in MPEG-4 format on an SD card. This
document refers to the SD card as _source storage_ and the files as
_raw videos_ or _source videos_. These files typically range between 2
and 4 GB in size.

In addition to the SD cards, the videographer used a high-capacity
portable hard disk to store processed videos and title cards. This
document refers to this device as _target storage_.

Due to the large file sizes, the videographer first transcoded the
source videos to target storage. Among other transformations described
later, the transcoding process compressed the raw videos.

We recommend structuring the target storage file system as follows:

        assemblies/
          DD/
            SS.mp4
        titles/
            copyright.*
            main.*
            sponsors.*
          sessions/
            DD/
              SS.*
        segments/
          DD/
            SS/
              GG.mp4
        sequences/
            DD/
              SS.sequence

Definitions:

  * `assemblies` contained the fully-assembled video files
  * `titles` contained the title card static graphics and animated
    video files
  * `segments` contained the session segment files after transcoding
    from source storage
  * `sequences` contained the text-formatted sequence files that
    FFmpeg reads to assemble a final video from its constituent videos
    (animated title cards and session segments)
  * `DD` was the zero-padded day number
  * `GG` was the zero-padded segment number in a given session
  * `SS` was the zero-padded session number on a given day

#### FFmpeg notes

[FFmpeg](https://ffmpeg.org/) is a powerful but notoriously complex
tool. The videographer needed considerable trial and error to arrive
at the options that follow.

Video processing invocations:

  * To transcode videos from the camera's raw format to smaller files,
    use these options:
	
     > -crf 30 -pix_fmt yuv420p -r 30 -vf scale=1280x720 -video_track_timescale 30k

     * `-crf 30` compresses the resulting video
     * `-pix_fmt yuv420p` specifies a pixel format
 	 * `-r 30` defines the frame rate _(30/second)_
	 * `-vf scale=1280x720` defines the resolution _(1280x720)_
	 * `-video_track_timescale 30k` defines the "clock tick" timebase
       _(30k ticks/second)_. The argument **must** match the animated
       title card's -- if not, the segment videos and cards will play
       at different rates

  * Specify `-ss h:m:s` as an input option to skip the first
    `hours:minutes:seconds` of the video. Similarly, specify `-t
    seconds` as an input option to stop encoding after `seconds`. Use
    these options to excise unwanted content from a segment.

  * To animate title cards, use these _input_ options (i.e., options
    that appear _before_ the `-i` option):
  
    > -f lavfi -i anullsrc=r=48000:cl=mono -loop 1

	* `-f lavfi` specifies the input filter _(`lavfi`)_
	* `-i anullsrc=r=48000:cl=mono` inserts a silent audio track
	* `-loop 1` loops the image as a video _(1 loop per second)_

  * Likewise, use these _output_ options (i.e., the options that
    appear _after_ the `-i` option):

    > -crf 30 -pix_fmt yuv420p -r 30 -t 6 -vcodec libx264 -vf scale=1280x720 -video_track_timescale 30k

     * `-crf 30` _same as transcoding_
     * `-pix_fmt yuv420p` _same as transcoding_
 	 * `-r 30` _same as transcoding_
     * `-t 6` specifies the running time _(6 seconds)_
	 * `-vcodec libx264` specifies the video codec _([H.264](https://en.wikipedia.org/wiki/Advanced_Video_Coding))_
	 * `-vf scale=1280x720` _same as transcoding_
	 * `-video_track_timescale 30k` _same as transcoding_

  * To generate the sequence files, create a text file listing the
    constituents in the order by which to concatenate them, in this
    format:
	
        file 'PATH'
        .
        .
        .

    See the [`concat` filter documentation](https://trac.ffmpeg.org/wiki/Concatenate)
	for details.

  * To assemble the final videos, use these options:
  
  > -safe 0 -f concat -i /sequence file/ -c copy /assembled file/.mp4
  
  * `-safe 0`: suppress errors about unsafe file paths
  * `-f concat`: specify the filter _(concatenation)_
  * `-i /sequence file/`: specify the input file _(sequence file path)_
  * `-c copy`: specify the output codec _(copy)_

#### Processing pipeline

The videographer processed the videos in the following sequence:

  * Create an inventory:
	* Sessions, speakers, and topics
    * Raw video files and how they map to sessions
  * Generate all of the title cards and animate them as MPEG-4 videos
  * For each day:
	* For each session:
	  * Transcode the raw video files from source storage to target
        storage
      * Generate an FFmpeg sequence file
      * Concatenate all of the session's constituent videos
  * Upload the videos to YouTube

#### Uploading to YouTube

We published assembled session videos to the [OPLSS YouTube
channel](https://www.youtube.com/channel/UCDe6N9R7U-RYWA57wzJQ2SQ). The
videographer needs a Google account and "manager" permissions on the
`OPLSS` brand account. See YouTube's [brand account
documentation](https://support.google.com/accounts/answer/7001996?co=GENIE.Platform%3DDesktop&hl=en).

YouTube recommends these [encoding
guidelines](https://support.google.com/youtube/answer/1722171?hl=en):

| *Parameter*  | *Value*                                                                            |
|--------------|------------------------------------------------------------------------------------|
| Container    | [MP4](https://en.wikipedia.org/wiki/MPEG-4_Part_14)                                |
| Video codec  | [H.264](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC)                            |
| Audio        | [AAC-LC](https://en.wikipedia.org/wiki/Advanced_Audio_Coding)                      |
| Frame rate   | _Any standard rate_                                                                |
| Bitrate      | _Varies by format_                                                                 |
| Resolution   | Preferably full HD, i.e., [1080p](https://en.wikipedia.org/wiki/1080p) / 1920x1080 |
| Aspect ratio | [16:9](https://en.wikipedia.org/wiki/16:9)                                         |
| Scan type    | [Progressive](https://en.wikipedia.org/wiki/Progressive_scan)                      |

See also YouTube's [resolution suggestions](https://support.google.com/youtube/answer/6375112).

A raw 90-minute 1920x1080 video may consume 8GB or more of storage,
and therefore requires substantial upstream bandwidth to upload. The
videographer used a wired connection in the U of O's computer science
building to upload the videos. An 8GB file required about 7 minutes on
that connection (20MB/s).
